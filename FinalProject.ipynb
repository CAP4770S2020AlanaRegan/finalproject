{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First obtain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y4CJ2heZZHA2"
   },
   "outputs": [],
   "source": [
    "# Pyspark SQL\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scikit\n",
    "import sklearn\n",
    "from scipy.io import loadmat\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pyspark\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): langdetect in ./anaconda3/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in ./anaconda3/lib/python3.5/site-packages (from langdetect)\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package (langdetect) in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Login information\n",
    "# username = # AWS Username\n",
    "# password = # AWS Password\n",
    "# region = \"us-east-1\" # Change if different from your AWS region\n",
    "\n",
    "\n",
    "# Dataset location\n",
    "# s3 = #s3a address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the AWS resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CluCfBnlZHA7"
   },
   "outputs": [],
   "source": [
    "sc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsAccessKeyId\", username)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsSecretAccessKey\", password)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.\" + region + \".amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"csv\").option(\"header\", \"true\").load(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = df.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small = sc.parallelize(rdd.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes non-English data from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def remove_nonenglish(row):\n",
    "    '''\n",
    "    Removes records that have invalid descriptions from the dataframe\n",
    "    Input: dataframe\n",
    "    Output: Cleaned up dataframe\n",
    "    '''\n",
    "    try:\n",
    "        lang=detect(row[1])\n",
    "        if (lang == 'en'): \n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def replace_punc_with_space(desc):\n",
    "    \n",
    "    upd_desc=''\n",
    "    \n",
    "    for i in range(len(desc)-1):\n",
    "        upd_desc+=desc[i]\n",
    "        if desc[i].islower() and desc[i+1].isupper():\n",
    "            upd_desc+=' '\n",
    "    \n",
    "    upd_desc+=desc[-1]\n",
    "    return upd_desc \n",
    "\n",
    "def remove_punc(row):\n",
    "    desc = row[1]\n",
    "    \n",
    "    desc=replace_punc_with_space(desc)    \n",
    "    desc=desc.lower() \n",
    "    desc = \"\".join([\" \" if char in ['.', ',', '?', '!', '(', ')', '/', ';', ':'] else char for char in desc])\n",
    "    desc = \"\".join([\"\" if char in ['\\''] else char for char in desc])\n",
    "    \n",
    "    lst = list(row)\n",
    "    lst[1] = desc\n",
    "    tup = tuple(lst)\n",
    "\n",
    "    return tup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small = small.filter(remove_nonenglish).map(remove_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genres, description, and authors converted to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genre_to_array(row):\n",
    "    genres = row[10]\n",
    "    glist = []\n",
    "    if(genres is not None): glist = genres.split('|')\n",
    "    \n",
    "    lst = list(row)\n",
    "    lst[10] = glist\n",
    "    tup = tuple(lst)\n",
    "\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def authors_to_array(row):\n",
    "    authors = row[0]\n",
    "    authorList = []\n",
    "    if(authors is not None): authorList = authors.split('|')\n",
    "    \n",
    "    lst = list(row)\n",
    "    lst[0] = authorList\n",
    "    tup = tuple(lst)\n",
    "\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def description_to_array(row):\n",
    "    description = row[1]\n",
    "    descriptionList = []\n",
    "    if(description is not None): descriptionList = description.split(' ')\n",
    "    \n",
    "    lst = list(row)\n",
    "    lst[1] = descriptionList\n",
    "    tup = tuple(lst)\n",
    "\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies the above processes to rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_filtered = rdd.filter(remove_nonenglish).map(remove_punc).map(genre_to_array).map(authors_to_array).map(description_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Suzanne Collins'], ['winning', 'will', 'make', 'you', 'famous', '', 'losing', 'means', 'certain', 'death', 'the', 'nation', 'of', 'panem', '', 'formed', 'from', 'a', 'post-apocalyptic', 'north', 'america', '', 'is', 'a', 'country', 'that', 'consists', 'of', 'a', 'wealthy', 'capitol', 'region', 'surrounded', 'by', '12', 'poorer', 'districts', '', 'early', 'in', 'its', 'history', '', 'a', 'rebellion', 'led', 'by', 'a', '13th', 'district', 'against', 'the', 'capitol', 'resulted', 'in', 'its', 'destruction', 'and', 'the', 'creation', 'of', 'an', 'annual', 'televised', 'event', 'known', 'as', 'the', 'hunger', 'games', '', 'in', 'punishment', '', 'and', 'as', 'a', 'reminder', 'of', 'the', 'power', 'and', 'grace', 'of', 'the', 'capitol', '', 'each', 'district', 'must', 'yield', 'one', 'boy', 'and', 'one', 'girl', 'between', 'the', 'ages', 'of', '12', 'and', '18', 'through', 'a', 'lottery', 'system', 'to', 'participate', 'in', 'the', 'games', '', 'the', 'tributes', 'are', 'chosen', 'during', 'the', 'annual', 'reaping', 'and', 'are', 'forced', 'to', 'fight', 'to', 'the', 'death', '', 'leaving', 'only', 'one', 'survivor', 'to', 'claim', 'victory', 'when', '16-year-old', 'katnisss', 'young', 'sister', '', 'prim', '', 'is', 'selected', 'as', 'district', '12s', 'female', 'representative', '', 'katniss', 'volunteers', 'to', 'take', 'her', 'place', '', 'she', 'and', 'her', 'male', 'counterpart', 'peeta', '', 'are', 'pitted', 'against', 'bigger', '', 'stronger', 'representatives', '', 'some', 'of', 'whom', 'have', 'trained', 'for', 'this', 'their', 'whole', 'lives', '', '', '', 'she', 'sees', 'it', 'as', 'a', 'death', 'sentence', '', 'but', 'katniss', 'has', 'been', 'close', 'to', 'death', 'before', '', 'for', 'her', '', 'survival', 'is', 'second', 'nature', ''], None, 'Hardcover', '9.78044E+12', '374 pages', '4.33', '5519135', '160706', 'The Hunger Games', ['Young Adult', 'Fiction', 'Science Fiction', 'Dystopia', 'Fantasy', 'Science Fiction'], 'https://images.gr-assets.com/books/1447303603l/2767052.jpg'), (['J.K. Rowling', 'Mary GrandPré'], ['there', 'is', 'a', 'door', 'at', 'the', 'end', 'of', 'a', 'silent', 'corridor', '', 'and', 'it’s', 'haunting', 'harry', 'pottter’s', 'dreams', '', 'why', 'else', 'would', 'he', 'be', 'waking', 'in', 'the', 'middle', 'of', 'the', 'night', '', 'screaming', 'in', 'terror', 'harry', 'has', 'a', 'lot', 'on', 'his', 'mind', 'for', 'this', '', 'his', 'fifth', 'year', 'at', 'hogwarts', '', 'a', 'defense', 'against', 'the', 'dark', 'arts', 'teacher', 'with', 'a', 'personality', 'like', 'poisoned', 'honey', '', 'a', 'big', 'surprise', 'on', 'the', 'gryffindor', 'quidditch', 'team', '', 'and', 'the', 'looming', 'terror', 'of', 'the', 'ordinary', 'wizarding', 'level', 'exams', '', 'but', 'all', 'these', 'things', 'pale', 'next', 'to', 'the', 'growing', 'threat', 'of', 'he-who-must-not-be-named---a', 'threat', 'that', 'neither', 'the', 'magical', 'government', 'nor', 'the', 'authorities', 'at', 'hogwarts', 'can', 'stop', 'as', 'the', 'grasp', 'of', 'darkness', 'tightens', '', 'harry', 'must', 'discover', 'the', 'true', 'depth', 'and', 'strength', 'of', 'his', 'friends', '', 'the', 'importance', 'of', 'boundless', 'loyalty', '', 'and', 'the', 'shocking', 'price', 'of', 'unbearable', 'sacrifice', 'his', 'fate', 'depends', 'on', 'them', 'alll', '', 'back', 'cover', ''], 'US Edition', 'Paperback', '9.78044E+12', '870 pages', '4.48', '2041594', '33264', 'Harry Potter and the Order of the Phoenix', ['Fantasy', 'Young Adult', 'Fiction'], 'https://images.gr-assets.com/books/1255614970l/2.jpg'), (['Harper Lee'], ['the', 'unforgettable', 'novel', 'of', 'a', 'childhood', 'in', 'a', 'sleepy', 'southern', 'town', 'and', 'the', 'crisis', 'of', 'conscience', 'that', 'rocked', 'it', '', 'to', 'kill', 'a', 'mockingbird', 'became', 'both', 'an', 'instant', 'bestseller', 'and', 'a', 'critical', 'success', 'when', 'it', 'was', 'first', 'published', 'in', '1960', '', 'it', 'went', 'on', 'to', 'win', 'the', 'pulitzer', 'prize', 'in', '1961', 'and', 'was', 'later', 'made', 'into', 'an', 'academy', 'award-winning', 'film', '', 'also', 'a', 'classic', 'compassionate', '', 'dramatic', '', 'and', 'deeply', 'moving', '', 'to', 'kill', 'a', 'mockingbird', 'takes', 'readers', 'to', 'the', 'roots', 'of', 'human', 'behavior', '-', 'to', 'innocence', 'and', 'experience', '', 'kindness', 'and', 'cruelty', '', 'love', 'and', 'hatred', '', 'humor', 'and', 'pathos', '', 'now', 'with', 'over', '18', 'million', 'copies', 'in', 'print', 'and', 'translated', 'into', 'forty', 'languages', '', 'this', 'regional', 'story', 'by', 'a', 'young', 'alabama', 'woman', 'claims', 'universal', 'appeal', '', 'harper', 'lee', 'always', 'considered', 'her', 'book', 'to', 'be', 'a', 'simple', 'love', 'story', '', 'today', 'it', 'is', 'regarded', 'as', 'a', 'masterpiece', 'of', 'american', 'literature', ''], '50th Anniversary', 'Paperback', '9.78006E+12', '324 pages', '4.27', '3745197', '79450', 'To Kill a Mockingbird', ['Classics', 'Fiction', 'Historical', 'Historical Fiction', 'Academic', 'School'], 'https://images.gr-assets.com/books/1361975680l/2657.jpg')]\n"
     ]
    }
   ],
   "source": [
    "print(rdd_filtered.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to dataframe with header names and cast datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rating: decimal(3,2) (nullable = true)\n",
      " |-- rating_count: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df = rdd_filtered.toDF(['author', 'description', 'edition', 'format', 'isbn13', 'pages', 'rating', 'rating_count', 'review_count', 'title', 'genres', 'image_url']) \\\n",
    "    .drop(\"edition\") \\\n",
    "    .drop(\"format\") \\\n",
    "    .drop(\"pages\") \\\n",
    "    .drop(\"isbn13\") \\\n",
    "    .drop(\"review_count\") \\\n",
    "    .drop(\"image_url\")\n",
    "\n",
    "books_df = books_df.withColumn(\"rating\", books_df[\"rating\"].cast(\"decimal(3,2)\")) \\\n",
    "    .withColumn(\"rating_count\", books_df[\"rating_count\"].cast(\"long\"))\n",
    "\n",
    "books_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------------+--------------------+--------------------+\n",
      "|              author|         description|rating|rating_count|               title|              genres|\n",
      "+--------------------+--------------------+------+------------+--------------------+--------------------+\n",
      "|   [Suzanne Collins]|[winning, will, m...|  4.33|     5519135|    The Hunger Games|[Young Adult, Fic...|\n",
      "|[J.K. Rowling, Ma...|[there, is, a, do...|  4.48|     2041594|Harry Potter and ...|[Fantasy, Young A...|\n",
      "|        [Harper Lee]|[the, unforgettab...|  4.27|     3745197|To Kill a Mocking...|[Classics, Fictio...|\n",
      "|   [Stephenie Meyer]|[about, three, th...|  3.58|     4281268|            Twilight|[Young Adult, Fan...|\n",
      "|      [Markus Zusak]|[trying, to, make...|  4.36|     1485632|      The Book Thief|[Historical, Hist...|\n",
      "+--------------------+--------------------+------+------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYdGn8tsZHBQ"
   },
   "source": [
    "### TF/IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources to learn more:\n",
    "\n",
    "* https://spark.apache.org/docs/latest/ml-features#tf-idf\n",
    "* https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "* https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
    "* https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf#scikit-learn-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------------+--------------------+--------------------+--------------------+\n",
      "|              author|         description|rating|rating_count|               title|              genres|                  tf|\n",
      "+--------------------+--------------------+------+------------+--------------------+--------------------+--------------------+\n",
      "|   [Suzanne Collins]|[winning, will, m...|  4.33|     5519135|    The Hunger Games|[Young Adult, Fic...|(262144,[1882,271...|\n",
      "|[J.K. Rowling, Ma...|[there, is, a, do...|  4.48|     2041594|Harry Potter and ...|[Fantasy, Young A...|(262144,[426,9639...|\n",
      "|        [Harper Lee]|[the, unforgettab...|  4.27|     3745197|To Kill a Mocking...|[Classics, Fictio...|(262144,[9639,101...|\n",
      "+--------------------+--------------------+------+------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "htf = HashingTF(inputCol=\"description\", outputCol=\"tf\")\n",
    "tf = htf.transform(books_df)\n",
    "tf.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: this takes a long time to complete. My internet may be bad right now or AWS may have a slowdown, but this took 5-10 minut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"tf\", outputCol=\"idf\")\n",
    "tfidf = idf.fit(tf).transform(tf)\n",
    "tfidf.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = tfidf.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_description = train.select('description').collect()\n",
    "train_rating = train.select('rating').collect()\n",
    "\n",
    "test_description = test.select('description').collect()\n",
    "test_rating = test.select('rating').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_genre = train.select('genres').collect()\n",
    "test_genre = test.select('genres').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(train_description, train_rating)\n",
    "score = model.score(test_description, test_rating)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "FinalProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
