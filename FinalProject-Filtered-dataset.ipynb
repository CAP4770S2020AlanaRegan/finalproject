{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First obtain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Y4CJ2heZZHA2"
   },
   "outputs": [],
   "source": [
    "# Pyspark SQL\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scikit\n",
    "import sklearn\n",
    "from scipy.io import loadmat\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): langdetect in ./anaconda3/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in ./anaconda3/lib/python3.5/site-packages (from langdetect)\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk in ./anaconda3/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package (langdetect) in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install langdetect\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Login information\n",
    "# username = # AWS Username\n",
    "# password = # AWS Password\n",
    "# region = \"us-east-1\" # Change if different from your AWS region\n",
    "\n",
    "\n",
    "\n",
    "# Dataset location\n",
    "# s3 = #S3 dataset URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the AWS resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CluCfBnlZHA7"
   },
   "outputs": [],
   "source": [
    "sc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsAccessKeyId\", username)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsSecretAccessKey\", password)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.\" + region + \".amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"csv\").option(\"header\", \"true\").load(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to confirm the dataset was obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = df.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def remove_nonenglish(row):\n",
    "    # Returns True if the tuple's description is written in English, false otherwise    \n",
    "    \n",
    "    try:\n",
    "        lang=detect(row[1])\n",
    "        if (lang == 'en'): \n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def replace_punc_with_space(desc):\n",
    "    # Returns an updated description string with punctuation directly between two letters replaced with a space\n",
    "    \n",
    "    new_desc=''\n",
    "    \n",
    "    for i in range(len(desc)-1):\n",
    "        new_desc+=desc[i]\n",
    "        if desc[i].islower() and desc[i+1].isupper():\n",
    "            new_desc+=' '\n",
    "    \n",
    "    new_desc+=desc[-1]\n",
    "    \n",
    "    return new_desc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_words(row):\n",
    "    # Returns tuple with description cleaned \n",
    "    # Removes punctuation, tokenizes words, stems them for comparision, filters out stop words\n",
    "    \n",
    "    desc = row[1] \n",
    "    \n",
    "    desc = replace_punc_with_space(desc) #Some words in descriptions are not separated by a space, but with punctuation\n",
    "    desc = desc.lower() #make all lowercase for easy comparing\n",
    "    \n",
    "    # split into words\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    words = word_tokenize(desc)\n",
    "    \n",
    "    # remove punctuation from each word\n",
    "    punc = str.maketrans('', '', string.punctuation)\n",
    "    no_punc = [word.translate(punc) for word in words]\n",
    "    \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words_alpha = [word for word in no_punc if word.isalpha()]\n",
    "    \n",
    "    \n",
    "    # filter out stop words\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words_alpha if not w in stop_words]    \n",
    "    \n",
    "    # stem the words\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    \n",
    "    lst = list(row)\n",
    "    lst[1] = words\n",
    "    tup = tuple(lst)\n",
    "\n",
    "    return tup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genre_to_array(row):\n",
    "    # Returns tuple with genres turned into an array\n",
    "    \n",
    "    genres = row[10]\n",
    "    glist = []\n",
    "    if(genres is not None): glist = genres.split('|')\n",
    "    \n",
    "    lst = list(row)\n",
    "    lst[10] = glist\n",
    "    tup = tuple(lst)\n",
    "\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_filtered = rdd.filter(remove_nonenglish).map(clean_words).map(genre_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Suzanne Collins',\n",
       "  ['winning',\n",
       "   'make',\n",
       "   'famous',\n",
       "   'losing',\n",
       "   'means',\n",
       "   'certain',\n",
       "   'deaththe',\n",
       "   'nation',\n",
       "   'panem',\n",
       "   'formed',\n",
       "   'postapocalyptic',\n",
       "   'north',\n",
       "   'america',\n",
       "   'country',\n",
       "   'consists',\n",
       "   'wealthy',\n",
       "   'capitol',\n",
       "   'region',\n",
       "   'surrounded',\n",
       "   'poorer',\n",
       "   'districts',\n",
       "   'early',\n",
       "   'history',\n",
       "   'rebellion',\n",
       "   'led',\n",
       "   'district',\n",
       "   'capitol',\n",
       "   'resulted',\n",
       "   'destruction',\n",
       "   'creation',\n",
       "   'annual',\n",
       "   'televised',\n",
       "   'event',\n",
       "   'known',\n",
       "   'hunger',\n",
       "   'games',\n",
       "   'punishment',\n",
       "   'reminder',\n",
       "   'power',\n",
       "   'grace',\n",
       "   'capitol',\n",
       "   'district',\n",
       "   'must',\n",
       "   'yield',\n",
       "   'one',\n",
       "   'boy',\n",
       "   'one',\n",
       "   'girl',\n",
       "   'ages',\n",
       "   'lottery',\n",
       "   'system',\n",
       "   'participate',\n",
       "   'games',\n",
       "   'tributes',\n",
       "   'chosen',\n",
       "   'annual',\n",
       "   'reaping',\n",
       "   'forced',\n",
       "   'fight',\n",
       "   'death',\n",
       "   'leaving',\n",
       "   'one',\n",
       "   'survivor',\n",
       "   'claim',\n",
       "   'victorywhen',\n",
       "   'katniss',\n",
       "   'young',\n",
       "   'sister',\n",
       "   'prim',\n",
       "   'selected',\n",
       "   'district',\n",
       "   'female',\n",
       "   'representative',\n",
       "   'katniss',\n",
       "   'volunteers',\n",
       "   'take',\n",
       "   'place',\n",
       "   'male',\n",
       "   'counterpart',\n",
       "   'peeta',\n",
       "   'pitted',\n",
       "   'bigger',\n",
       "   'stronger',\n",
       "   'representatives',\n",
       "   'trained',\n",
       "   'whole',\n",
       "   'lives',\n",
       "   'sees',\n",
       "   'death',\n",
       "   'sentence',\n",
       "   'katniss',\n",
       "   'close',\n",
       "   'death',\n",
       "   'survival',\n",
       "   'second',\n",
       "   'nature'],\n",
       "  None,\n",
       "  'Hardcover',\n",
       "  '9.78044E+12',\n",
       "  '374 pages',\n",
       "  '4.33',\n",
       "  '5519135',\n",
       "  '160706',\n",
       "  'The Hunger Games',\n",
       "  ['Young Adult',\n",
       "   'Fiction',\n",
       "   'Science Fiction',\n",
       "   'Dystopia',\n",
       "   'Fantasy',\n",
       "   'Science Fiction'],\n",
       "  'https://images.gr-assets.com/books/1447303603l/2767052.jpg'),\n",
       " ('J.K. Rowling|Mary GrandPré',\n",
       "  ['door',\n",
       "   'end',\n",
       "   'silent',\n",
       "   'corridor',\n",
       "   'haunting',\n",
       "   'harry',\n",
       "   'dreams',\n",
       "   'else',\n",
       "   'would',\n",
       "   'waking',\n",
       "   'middle',\n",
       "   'night',\n",
       "   'screaming',\n",
       "   'terror',\n",
       "   'harry',\n",
       "   'lot',\n",
       "   'mind',\n",
       "   'fifth',\n",
       "   'year',\n",
       "   'hogwarts',\n",
       "   'defense',\n",
       "   'dark',\n",
       "   'arts',\n",
       "   'teacher',\n",
       "   'personality',\n",
       "   'like',\n",
       "   'poisoned',\n",
       "   'honey',\n",
       "   'big',\n",
       "   'surprise',\n",
       "   'gryffindor',\n",
       "   'quidditch',\n",
       "   'team',\n",
       "   'looming',\n",
       "   'terror',\n",
       "   'ordinary',\n",
       "   'wizarding',\n",
       "   'level',\n",
       "   'exams',\n",
       "   'things',\n",
       "   'pale',\n",
       "   'next',\n",
       "   'growing',\n",
       "   'threat',\n",
       "   'hewhomustnotbenamed',\n",
       "   'threat',\n",
       "   'neither',\n",
       "   'magical',\n",
       "   'government',\n",
       "   'authorities',\n",
       "   'hogwarts',\n",
       "   'stopas',\n",
       "   'grasp',\n",
       "   'darkness',\n",
       "   'tightens',\n",
       "   'harry',\n",
       "   'must',\n",
       "   'discover',\n",
       "   'true',\n",
       "   'depth',\n",
       "   'strength',\n",
       "   'friends',\n",
       "   'importance',\n",
       "   'boundless',\n",
       "   'loyalty',\n",
       "   'shocking',\n",
       "   'price',\n",
       "   'unbearable',\n",
       "   'sacrificehis',\n",
       "   'fate',\n",
       "   'depends',\n",
       "   'alll',\n",
       "   'back',\n",
       "   'cover'],\n",
       "  'US Edition',\n",
       "  'Paperback',\n",
       "  '9.78044E+12',\n",
       "  '870 pages',\n",
       "  '4.48',\n",
       "  '2041594',\n",
       "  '33264',\n",
       "  'Harry Potter and the Order of the Phoenix',\n",
       "  ['Fantasy', 'Young Adult', 'Fiction'],\n",
       "  'https://images.gr-assets.com/books/1255614970l/2.jpg'),\n",
       " ('Harper Lee',\n",
       "  ['unforgettable',\n",
       "   'novel',\n",
       "   'childhood',\n",
       "   'sleepy',\n",
       "   'southern',\n",
       "   'town',\n",
       "   'crisis',\n",
       "   'conscience',\n",
       "   'rocked',\n",
       "   'kill',\n",
       "   'mockingbird',\n",
       "   'became',\n",
       "   'instant',\n",
       "   'bestseller',\n",
       "   'critical',\n",
       "   'success',\n",
       "   'first',\n",
       "   'published',\n",
       "   'went',\n",
       "   'win',\n",
       "   'pulitzer',\n",
       "   'prize',\n",
       "   'later',\n",
       "   'made',\n",
       "   'academy',\n",
       "   'awardwinning',\n",
       "   'film',\n",
       "   'also',\n",
       "   'classiccompassionate',\n",
       "   'dramatic',\n",
       "   'deeply',\n",
       "   'moving',\n",
       "   'kill',\n",
       "   'mockingbird',\n",
       "   'takes',\n",
       "   'readers',\n",
       "   'roots',\n",
       "   'human',\n",
       "   'behavior',\n",
       "   'innocence',\n",
       "   'experience',\n",
       "   'kindness',\n",
       "   'cruelty',\n",
       "   'love',\n",
       "   'hatred',\n",
       "   'humor',\n",
       "   'pathos',\n",
       "   'million',\n",
       "   'copies',\n",
       "   'print',\n",
       "   'translated',\n",
       "   'forty',\n",
       "   'languages',\n",
       "   'regional',\n",
       "   'story',\n",
       "   'young',\n",
       "   'alabama',\n",
       "   'woman',\n",
       "   'claims',\n",
       "   'universal',\n",
       "   'appeal',\n",
       "   'harper',\n",
       "   'lee',\n",
       "   'always',\n",
       "   'considered',\n",
       "   'book',\n",
       "   'simple',\n",
       "   'love',\n",
       "   'story',\n",
       "   'today',\n",
       "   'regarded',\n",
       "   'masterpiece',\n",
       "   'american',\n",
       "   'literature'],\n",
       "  '50th Anniversary',\n",
       "  'Paperback',\n",
       "  '9.78006E+12',\n",
       "  '324 pages',\n",
       "  '4.27',\n",
       "  '3745197',\n",
       "  '79450',\n",
       "  'To Kill a Mockingbird',\n",
       "  ['Classics',\n",
       "   'Fiction',\n",
       "   'Historical',\n",
       "   'Historical Fiction',\n",
       "   'Academic',\n",
       "   'School'],\n",
       "  'https://images.gr-assets.com/books/1361975680l/2657.jpg')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_filtered.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYdGn8tsZHBQ"
   },
   "source": [
    "### TF/IDF\n",
    "\n",
    "One thing that will need to happen is to use regex to transform the genres into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book_authors',\n",
       " 'book_desc',\n",
       " 'book_edition',\n",
       " 'book_format',\n",
       " 'book_isbn',\n",
       " 'book_pages',\n",
       " 'book_rating',\n",
       " 'book_rating_count',\n",
       " 'book_review_count',\n",
       " 'book_title',\n",
       " 'genres',\n",
       " 'image_url']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_df = df.schema.names\n",
    "header_df\n",
    "\n",
    "# TO DO\n",
    "# SEE ERROR BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing datsets\n",
    "\n",
    "Currently using ~10% of the dataset (can be adjusted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KDzYkE5MZHBF"
   },
   "outputs": [],
   "source": [
    "# train, test = df.randomSplit([0.1, 0.9])\n",
    "\n",
    "# train_desc = train.select('book_desc').collect()\n",
    "# train_genre = train.select('genres').collect()\n",
    "\n",
    "# test_desc = test.select('book_desc').collect()\n",
    "# test_genre = test.select('genres').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = MultinomialNB().fit(train_desc, train_genre)\n",
    "# score = model.score(test_desc, test_genre)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "FinalProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
